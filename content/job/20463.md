---
company: EPAM SYSTEMS PTE. LTD.
company_logo: https://s3-ap-southeast-1.amazonaws.com/ojmp-data/a30da25ae34f91f4ffe0322971c262da/epam-systems.jpg
company_url: null
description: "Description\nWe are looking for an energetic Software Engineer specialized\
  \ in Big Data in Singapore to make the team stronger.\nWe Value\n\nValue the individuals\
  \ \u2013 We encourage and motivate people to grow. We perceive our people as a source\
  \ of our success\nStrive for excellence \u2013 We strive for the highest standards\
  \ of excellence and continuously learn. We take pride in our engineering and accomplishments\n\
  Act as a team \u2013 We treat one another with respect and encourage the best ideas\
  \ to come from anywhere within the organization. We value our diversity\nFocus on\
  \ Customers \u2013 We build long term customer relationships, as we strive to always\
  \ understand our customers' business and needs\nAct with integrity \u2013 We operate\
  \ legally, honestly and ethically. We take responsibility for our actions.\n\nResponsibilities\n\
  \nPlay a developer role\nWrite high quality and testable code following clean code\
  \ principles\nImplement functionality by following defined software development\
  \ process without direct supervision\nRead and understand project and requirement\
  \ documentation\nCreate documentation describing his/her code\nParticipate in Agile\
  \ Scrum activities: daily standup, demo session, retrospective, planning, etc.\n\
  \nRequirements\n\nPolytechnic Diploma or above in Computer Science\nMinimum 3 years\
  \ of experience in software engineering and Big Data\nAdvanced knowledge at least\
  \ one programming language such as Java, Python, Scala\nFamiliar with SQL, Bash\n\
  Experienced in any of big data technologies and frameworks below:\n\n\nSpark, Spark\
  \ Streaming, Kafka/ Kafka Streams, Hadoop, Yarn, HDFS, Hive, Airflow, Jupyter\n\
  Parquet, ORC, AVRO, CarbonData\nLambda, Kappa, Data Lake\nNoSQL Data Bases\nData\
  \ platform\nMachine learning\n\n\nSoftware Professional with experience in IT mostly\
  \ with JVM based technologies and frameworks\nHas background with different platforms\
  \ and strong focus on back-ends / Big Data / Analytics Solutions\nCore professional\
  \ expertise includes: Platform Architecture, Data Pipelines Architecture, Infrastructure\
  \ Deployment and Management\nAble to support existing and potential customers with\
  \ requirements capture, solutions architecture, system design, solution prototyping\n\
  Experience with building traditional Cloud Data Warehouses, Data Lakes. Close and\
  \ intensive work on previous projects with Containers and Resource Management systems:\
  \ Docker, Kubernetes, Yarn.\nDesigned, prototype and adjust end to end solution\n\
  Designed and implemented set of ingestion workflow to parse, transform and validate\
  \ input data\nDesigned and developed independent CI/CD pipelines\nProvided technical\
  \ guidance for the support team\nParticipated in communication with customer on\
  \ every phase\n"
id: 20463
job_tags:
- sql
- machine-learning
- agile
- hadoop
- hive
- continuous-integration
- big-data
- apache
- continuous-delivery
- data-warehouse-architecture
posted_date: '2021-01-25T10:30:29.000Z'
source: myCareersFuture
title: Software Engineer (Big Data)
website: https://www.mycareersfuture.gov.sg/job/information-technology/software-engineer-epam-systems-fddb8b12dddb22b0cee2205aa8f2bcf1
---
